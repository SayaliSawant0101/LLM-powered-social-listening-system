{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awoDe8Wivt2Z",
        "outputId": "9083c0c1-e12e-4284-a09b-e7a4f5b4640d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.12/dist-packages (1.40.35)\n",
            "Requirement already satisfied: botocore<1.41.0,>=1.40.35 in /usr/local/lib/python3.12/dist-packages (from boto3) (1.40.35)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from boto3) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.35->boto3) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.35->boto3) (2.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.35->boto3) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install boto3\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import boto3\n",
        "from datetime import datetime\n",
        "from typing import Optional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "APIFY_TOKEN   = os.getenv(\"APIFY_TOKEN\", \"i\")\n",
        "RUN_ID        = os.getenv(\"RUN_ID\", \"w\")\n",
        "EXPORT_FORMAT = os.getenv(\"EXPORT_FORMAT\", \"json\")\n",
        "OUT_FILE      = os.getenv(\"OUT_FILE\", \"\")\n",
        "\n",
        "AWS_BUCKET = os.getenv(\"AWS_BUCKET\", \"capstone-raw-twitterdata-cs668\")\n",
        "AWS_REGION = os.getenv(\"AWS_REGION\", \"us-east-1\")\n",
        "S3_KEY     = os.getenv(\"S3_KEY\", \"\")\n",
        "\n",
        "WAIT_IF_NOT_DONE = True\n",
        "POLL_SECS = 6\n",
        "TIMEOUT_MINS = 45\n",
        "\n",
        "AWS_ACCESS_KEY_ID     = \"AKIAR5WUAXE\"\n",
        "AWS_SECRET_ACCESS_KEY = \"anA423Ym1xgrsonr\"\n",
        "AWS_SESSION_TOKEN     = \"\"\n",
        "\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = AWS_ACCESS_KEY_ID\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET_ACCESS_KEY\n",
        "if AWS_SESSION_TOKEN:\n",
        "    os.environ[\"AWS_SESSION_TOKEN\"] = AWS_SESSION_TOKEN\n",
        "os.environ[\"AWS_DEFAULT_REGION\"] = AWS_REGION\n",
        "\n"
      ],
      "metadata": {
        "id": "NuUvopyVv9dz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_run(run_id: str, token: str) -> dict:\n",
        "    r = requests.get(f\"https://api.apify.com/v2/actor-runs/{run_id}\",  #fetching data from Apify runs\n",
        "                     params={\"token\": token}, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    return r.json()[\"data\"]\n",
        "\n",
        "def export_dataset_stream(dataset_id: str, token: str, export_format: str, clean=True, bom=False, fields: Optional[list]=None):\n",
        "    base = f\"https://api.apify.com/v2/datasets/{dataset_id}/items\".\n",
        "    params = {\"token\": token, \"format\": export_format,\n",
        "              \"clean\": str(clean).lower(), \"bom\": str(bom).lower()}\n",
        "    if fields:\n",
        "        params[\"fields\"] = \",\".join(fields)\n",
        "    resp = requests.get(base, params=params, stream=True, timeout=300)\n",
        "    resp.raise_for_status()\n",
        "    return resp\n",
        "\n",
        "def save_stream_to_file(resp, filepath: str):\n",
        "    with open(filepath, \"wb\") as f:\n",
        "        for chunk in resp.iter_content(chunk_size=1024 * 1024):\n",
        "            if chunk:\n",
        "                f.write(chunk)\n",
        "\n",
        "def upload_stream_to_s3(resp, bucket: str, key: str, region: str = \"us-east-1\"):\n",
        "    s3 = boto3.client(\"s3\", region_name=region)\n",
        "    s3.upload_fileobj(resp.raw, bucket, key)"
      ],
      "metadata": {
        "id": "CHggPVfEylMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = get_run(RUN_ID, APIFY_TOKEN)\n",
        "\n",
        "if run[\"status\"] != \"SUCCEEDED\":\n",
        "    raise RuntimeError(f\"Run {RUN_ID} not SUCCEEDED (status={run['status']}).\")\n",
        "\n",
        "dataset_id = run[\"defaultDatasetId\"]\n",
        "finished_at = (run.get(\"finishedAt\") or \"\")[:10] or datetime.utcnow().strftime(\"%Y-%m-%d\")\n",
        "print(\"Dataset ID:\", dataset_id)\n",
        "\n",
        "out_file = OUT_FILE or f\"apify_run_{RUN_ID}.{EXPORT_FORMAT}\"\n",
        "s3_key   = S3_KEY   or f\"raw/run={RUN_ID}-dt={finished_at}.{EXPORT_FORMAT}\"  #file name\n",
        "\n",
        "with export_dataset_stream(dataset_id, APIFY_TOKEN, EXPORT_FORMAT) as resp:\n",
        "    if AWS_BUCKET:\n",
        "        print(f\"Uploading to s3://{AWS_BUCKET}/{s3_key} ...\")\n",
        "        upload_stream_to_s3(resp, AWS_BUCKET, s3_key, region=AWS_REGION)\n",
        "        print(f\"✅ Uploaded to s3://{AWS_BUCKET}/{s3_key}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytVt6MvuyyeJ",
        "outputId": "9683cc59-1c4c-49de-9065-6e835e6060ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ID: hl2yN4XSdn\n",
            "Uploading to s3://capstone-raw-twitterdata-cs668/raw/run=w402mc7R8885YMfEy-dt=2025-09-21.json ...\n",
            "✅ Uploaded to s3://capstone-raw-twitterdata-cs668/raw/run=w402mc7R8885YMfEy-dt=2025-09-21.json\n"
          ]
        }
      ]
    }
  ]
}
