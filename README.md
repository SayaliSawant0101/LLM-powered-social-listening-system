# LLM-powered Social Listening System

> **ðŸ“‹ [View Project Timeline & Milestones on Notion](https://www.notion.so/LLM-powered-Social-Listening-System-28abe5c2ca3180e7a35defa1c99e44e8)**

# Walmart Social Media Listener

Endâ€‘toâ€‘end pipeline for Twitter/X listening about Walmart: cleaning â†’ sentiment â†’ aspectâ€‘based analysis â†’ unsupervised themes â†’ **LLM executive summaries** â†’ interactive demo.

## 1) Quickstart

```bash
# clone or unzip locally, then:
python3 -m venv .venv       # Windows: python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -U pip
pip install -r requirements.txt

# set env
cp .env.example .env        # Windows: copy .env.example .env
# open .env and set OPENAI_API_KEY="YOUR_OPENAI_API_KEY"
```

### Run the frontend
```bash
cd frontend
npm run dev
```

### CLI summarizer
```bash
python scripts/generate_summary.py   --data data/tweets_clean.parquet   --start 2025-07-01 --end 2025-07-31 --keyword "delivery"
```

## 2) Repo layout & where to paste notebook code

```
walmart_social_listener/
â”œâ”€ frontend/                       # React frontend (Vite + Tailwind CSS)
â”œâ”€ data/                          # Put your CSV/XLSX/Parquet here (kept out of git)
â”œâ”€ notebooks/
â”‚  â””â”€ Walmart_Social_Media_Listener_V1.ipynb   # Move your current ipynb here
â”œâ”€ scripts/
â”‚  â”œâ”€ run_pipeline.py             # Orchestrate dataâ†’featuresâ†’topics (paste pipeline steps)
â”‚  â””â”€ generate_summary.py         # Batch LLM summaries from a file
â”œâ”€ src/
â”‚  â”œâ”€ features/
â”‚  â”‚  â”œâ”€ clean.py                 # â¬…ï¸ Paste your cleaning/prep utilities
â”‚  â”‚  â”œâ”€ sentiment.py             # â¬…ï¸ Paste sentiment functions (CardiffNLP, etc.)
â”‚  â”‚  â”œâ”€ absa.py                  # â¬…ï¸ Paste aspect-based code here
â”‚  â”‚  â””â”€ topics.py                # â¬…ï¸ Paste BERTopic/topic modeling code here
â”‚  â”œâ”€ llm/
â”‚  â”‚  â””â”€ summary.py               # LLM executive summary logic (already scaffolded)
â”‚  â””â”€ utils/
â”‚     â””â”€ text.py                  # Small helpers (tokenize, normalize, etc.)
â”œâ”€ .env.example                   # Environment variables template
â”œâ”€ requirements.txt
â””â”€ README.md
```

### Mapping your notebook sections â†’ files
- **Data loading/cleaning** â†’ `src/features/clean.py`
- **Sentiment** â†’ `src/features/sentiment.py`
- **Aspectâ€‘Based** â†’ `src/features/absa.py`
- **Topics/BERTopic** â†’ `src/features/topics.py`
- **Helper functions** â†’ `src/utils/text.py`
- **LLM Summary** â†’ use/extend `src/llm/summary.py`
- **Pipeline orchestration** (readâ†’processâ†’save) â†’ `scripts/run_pipeline.py`

> Tip: copy code cellâ€‘byâ€‘cell into these files, turn notebook variables into function parameters, and return DataFrames.

## 3) Git workflow (local â†’ GitHub)

```bash
# initialize and first commit
git init
git add .
git commit -m "init: scaffold social listener + LLM summary app"

# add remote (replace with your repo URL)
git branch -M main
git remote add origin https://github.com/<you>/walmart-social-listener.git
git push -u origin main

# day-to-day
git pull            # bring latest from remote
git checkout -b feat/llm-summary
# ... edit, run, test ...
git add -A
git commit -m "feat: add LLM executive summary + React frontend"
git push -u origin feat/llm-summary
# open a PR, review, merge
```

## 4) Deploy a live demo

**Frontend (React):**
1. Build the frontend: `cd frontend && npm run build`
2. Deploy to Netlify/Vercel/Cloudflare Pages
3. Set environment variables for API endpoints

**Backend (Node.js/Express):**
1. Deploy `server/server.js` to services like Railway, Render, or Heroku
2. Ensure Python dependencies are available for theme generation scripts
3. Set environment variables: `OPENAI_API_KEY`, data paths, etc.

## 5) Expected columns

The system expects parquet files (CSV/XLSX/Parquet) with at least:
- `clean_tweet` or `text` (str): cleaned text
- `createdat` or `created_at` or `date` (datetime/ISO or parseable string)
- Optional: `sentiment_label`, `aspect_dominant`, `theme`, etc.

## 6) OpenAI usage
We use the official SDK (`openai`), via the **Responses API** by default. See comments in `src/llm/summary.py` to switch to Chat Completions if you prefer.
